#!/usr/bin/env python3
import cv2
import time
import os
from ultralytics import YOLO

MODEL_PATH = "/home/tulja/smart_glasses/yolov8n.pt"
SPEAK_COOLDOWN = 2.0
CONF_THRESHOLD = 0.45

print("Loading YOLO model...")
model = YOLO(MODEL_PATH)

cap = cv2.VideoCapture(0)
cap.set(cv2.CAP_PROP_FRAME_WIDTH, 320)
cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 240)
time.sleep(1)

last_spoken = ""
last_time = 0

def speak(msg):
    os.system(f'espeak "{msg}" 2>/dev/null')

def get_direction(x_center, frame_width):
    if x_center < frame_width*0.33:
        return "left"
    elif x_center > frame_width*0.66:
        return "right"
    else:
        return "ahead"

print("Starting detection...")

while True:
    ret, frame = cap.read()
    if not ret:
        continue

    results = model.predict(frame, imgsz=320, conf=CONF_THRESHOLD, verbose=False)

    if len(results[0].boxes) == 0:
        continue

    # pick the largest bbox (most stable)
    largest_box = max(results[0].boxes, key=lambda b: b.xyxy[0][2] - b.xyxy[0][0])

    cls_id = int(largest_box.cls[0])
    label = model.names[cls_id]

    x1, y1, x2, y2 = largest_box.xyxy[0]
    x_center = (x1 + x2) / 2

    direction = get_direction(x_center, frame.shape[1])
    speak_text = f"{label} on your {direction}"

    now = time.time()
    if speak_text != last_spoken or now - last_time > SPEAK_COOLDOWN:
        print(speak_text)
        speak(speak_text)
        last_spoken = speak_text
        last_time = now

    time.sleep(0.05)
